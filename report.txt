================Task 1================
Model 1 average validation MSE:
Mean squared error      5.90529359049289
--------------------
Modle 1 testing MES:
Mean squared error      22.140613888888875

Experiment 1 : 
Model 1 average validation MSE:
i = 23	Mean squared error	6.050370379164231
--------------------
Modle 1 testing MES:
i = 23	Mean squared error	22.250283203125

>> In this task, I use RandomForestRegressor as the regression model. 
>> The width of the forest is 100, and the random seed is as 42.
>> Due to I have set the random seed, the results are reproducable. 
>> I also use RFE to reduce features. It helps me selecting 23 features among 56 features.
>> (some categorical features would expand to several features due to the one hot encoding)
>> these 23 featrures are as below : 
['num__age' 'num__Medu' 'num__Fedu' 'num__traveltime' 'num__studytime'
 'num__failures' 'num__famrel' 'num__freetime' 'num__goout' 'num__Dalc'
 'num__Walc' 'num__health' 'num__absences' 'cat__school_GP' 'cat__sex_F'
 'cat__Mjob_other' 'cat__Fjob_services' 'cat__reason_other'
 'cat__reason_reputation' 'cat__edusupport_family' 'cat__higher_no'
 'cat__higher_yes' 'cat__romantic_no']
>> Besides, I do the normalization for numerical features. 
>> I scaled them into the range(-1, 1)
>> It would take about 10 more seconds to train the model

Experiment 2 : 
================Task 1================
Model 1 average validation MSE:
i = 1   Mean squared error      7.089611238770128
i = 2   Mean squared error      7.637682075498438
i = 3   Mean squared error      7.746573946079392
i = 4   Mean squared error      8.454337290137829
i = 5   Mean squared error      9.035146769007497
i = 6   Mean squared error      8.528331753354717
i = 7   Mean squared error      8.291501058583515
i = 8   Mean squared error      7.873245186442723
i = 9   Mean squared error      7.400858788941369
i = 10  Mean squared error      7.388126063575557
i = 11  Mean squared error      6.935939421988441
i = 12  Mean squared error      6.773559348425222
i = 13  Mean squared error      6.411914260666277
i = 14  Mean squared error      6.321714713617769
i = 15  Mean squared error      6.171524289888955
i = 16  Mean squared error      6.081452378725892
i = 17  Mean squared error      6.015909631794273
i = 18  Mean squared error      5.9451361104617195
i = 19  Mean squared error      5.915377971946231
i = 20  Mean squared error      5.920849424313267
i = 21  Mean squared error      5.940920046756283
i = 22  Mean squared error      5.881622706019873
i = 23  Mean squared error      5.853391323787259
i = 24  Mean squared error      5.85507754529515
i = 25  Mean squared error      5.773024155464641
i = 26  Mean squared error      5.818939336645237
i = 27  Mean squared error      5.816001893629456
i = 28  Mean squared error      5.828644576271186
i = 29  Mean squared error      5.818890084745761
i = 30  Mean squared error      5.842908068381063
i = 31  Mean squared error      5.811675450029222
i = 32  Mean squared error      5.8310703477498524
i = 33  Mean squared error      5.9179706136762125
i = 34  Mean squared error      5.87920033898305
i = 35  Mean squared error      5.913230338983049
i = 36  Mean squared error      5.8596146610169475
i = 37  Mean squared error      5.850752133255406
i = 38  Mean squared error      5.898189535359438
i = 39  Mean squared error      5.851188427819989
i = 40  Mean squared error      5.844506230274693
i = 41  Mean squared error      5.845513854471068
i = 42  Mean squared error      5.901515745178258
i = 43  Mean squared error      5.886120561075394
i = 44  Mean squared error      5.881298582700174
i = 45  Mean squared error      5.936038796025715
i = 46  Mean squared error      5.857915280537696
i = 47  Mean squared error      5.858247516072472
Mean squared error      5.773024155464641
self.optimized_feature_number = 25
self.optimized_features = Index(['school', 'sex', 'age', 'address', 'Medu', 'Fedu', 'traveltime',
       'studytime', 'failures', 'higher', 'internet', 'romantic', 'famrel',
       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'Mjob_other',
       'Fjob_services', 'reason_other', 'reason_reputation',
       'edusupport_family', 'edusupport_no'],
      dtype='object')
--------------------
Modle 1 testing MES:
Selected features: Index(['school', 'sex', 'age', 'address', 'Medu', 'Fedu', 'traveltime',
       'studytime', 'failures', 'higher', 'internet', 'romantic', 'famrel',
       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'Mjob_other',
       'Fjob_services', 'reason_other', 'reason_reputation',
       'edusupport_family', 'edusupport_no'],
      dtype='object')
Mean squared error      22.903082812499996

In this Experiment, I set the width of the RandomForestRegressor as 100, and iterate that from 1 to the len of then features. 
Furthermore, I set all the binary attributes as True/False, and normalization for all numeric features.
Moreover, I use sigmoid for those numeric features. 
It's supposed to have a better result than Experiment 1, because the features engineering is more reasonable. 
However, it only gains the better performance on training set, and worse MSE on testing set. 
So, I'm going to move forward to the next experiment. 

Experiment 3 :
I adopted feature interaction method in DataParser. 
>>> Code
>>> self.data['parents_education'] = self.data['Medu'] * self.data['Fedu']
>>> self.data['famrel_freetime'] = self.data['famrel'] * self.data['freetime']
Unfortunately, the result is not better than the previous one. 

Model 1 average validation MSE:
Mean squared error      6.044770087668031
self.optimized_feature_number = 32
self.optimized_features = Index(['school', 'sex', 'address', 'traveltime', 'studytime', 'failures',
       'nursery', 'higher', 'internet', 'romantic', 'goout', 'Dalc', 'Walc',
       'health', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Fjob_services',
       'reason_home', 'reason_reputation', 'edusupport_family',
       'edusupport_no', 'poly_0', 'poly_1', 'poly_2', 'poly_3', 'poly_4',
       'poly_5', 'poly_6', 'poly_7', 'poly_8', 'poly_9'],
      dtype='object')
--------------------
Modle 1 testing MES:
Selected features: Index(['school', 'sex', 'address', 'traveltime', 'studytime', 'failures',
       'nursery', 'higher', 'internet', 'romantic', 'goout', 'Dalc', 'Walc',
       'health', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Fjob_services',
       'reason_home', 'reason_reputation', 'edusupport_family',
       'edusupport_no', 'poly_0', 'poly_1', 'poly_2', 'poly_3', 'poly_4',
       'poly_5', 'poly_6', 'poly_7', 'poly_8', 'poly_9'],
      dtype='object')
Mean squared error      23.26792812499999


Experiment 4 :
I fount that Experiment 3 removes the continuous numeric features becaues of the generated polys. 
However, thouse features are still important to the prediction model.
So, I gain the validation MSE 5.963601402688487
and the testing MSE : 22.47025625
================Task 1================
Model 1 average validation MSE:
i = 55  Mean squared error      6.0563512478082995
i = 54  Mean squared error      6.060761396843951
i = 53  Mean squared error      6.011387749853886
i = 52  Mean squared error      5.990957498538867
i = 51  Mean squared error      6.059526186440678
i = 50  Mean squared error      6.003548217416716
i = 49  Mean squared error      6.045407819988311
i = 48  Mean squared error      5.996737624196378
i = 47  Mean squared error      6.048106043249562
i = 46  Mean squared error      6.031638334307424
i = 45  Mean squared error      6.014926744593806
i = 44  Mean squared error      6.033980020455874
i = 43  Mean squared error      5.97666385447107
i = 42  Mean squared error      6.032315271770895
i = 41  Mean squared error      5.987807387492693
i = 40  Mean squared error      5.99494748100526
i = 39  Mean squared error      5.97136098188194
i = 38  Mean squared error      5.990226116306253
i = 37  Mean squared error      6.000173705435418
i = 36  Mean squared error      5.9756161630625355
i = 35  Mean squared error      6.031738386908241
i = 34  Mean squared error      5.9802239421391
i = 33  Mean squared error      5.963601402688487
i = 32  Mean squared error      5.977769070718878
i = 31  Mean squared error      6.039895350672121
i = 30  Mean squared error      6.043569114552893
i = 29  Mean squared error      6.059676846873174
i = 28  Mean squared error      6.047331566335475
i = 27  Mean squared error      6.086767367036822
i = 26  Mean squared error      6.008405581531268
i = 25  Mean squared error      6.0106218234950335
i = 24  Mean squared error      6.02046116014027
i = 23  Mean squared error      6.055894772063121
i = 22  Mean squared error      6.108824047340738
i = 21  Mean squared error      6.076585192869668
i = 20  Mean squared error      6.0928142226767985
i = 19  Mean squared error      6.02660815020456
i = 18  Mean squared error      5.994198693746349
i = 17  Mean squared error      6.125575286382232
i = 16  Mean squared error      6.138640169491526
i = 15  Mean squared error      6.216002784921099
i = 14  Mean squared error      6.196161186440678
i = 13  Mean squared error      6.305763997662186
i = 12  Mean squared error      6.488131011104618
i = 11  Mean squared error      6.519121621858564
i = 10  Mean squared error      6.773942493343725
i = 9   Mean squared error      6.963566617598547
i = 8   Mean squared error      6.97131872191782
i = 7   Mean squared error      6.898515772037956
i = 6   Mean squared error      7.2285272759673544
i = 5   Mean squared error      8.02525501232898
i = 4   Mean squared error      8.662909477953084
i = 3   Mean squared error      8.5977337420643
i = 2   Mean squared error      7.743998412188061
i = 1   Mean squared error      7.089611238770128
Mean squared error      5.963601402688487
self.optimized_feature_number = 33
self.optimized_features = Index(['school', 'sex', 'age', 'address', 'studytime', 'failures', 'nursery',
       'higher', 'internet', 'romantic', 'goout', 'Dalc', 'Walc', 'health',
       'absences', 'Mjob_health', 'Mjob_other', 'Mjob_services',
       'Fjob_services', 'reason_home', 'reason_other', 'reason_reputation',
       'edusupport_family', 'edusupport_no', 'parents_education',
       'famrel_freetime', 'poly_0', 'poly_1', 'poly_2', 'poly_3', 'poly_6',
       'poly_8', 'poly_9'],
      dtype='object')
--------------------
Modle 1 testing MES:
Mean squared error      22.47025625

Experiment 5:
I adjusted the RandomForestRegressor width to 150, and the better performance came out.

================Task 1================
Model 1 average validation MSE:
i = 55  Mean squared error      6.002412625495162
i = 54  Mean squared error      5.995953956750438
i = 53  Mean squared error      5.988410261705304
i = 52  Mean squared error      5.97089927917397
i = 51  Mean squared error      6.006413642444313
i = 50  Mean squared error      5.990333684005453
i = 49  Mean squared error      5.999444157412819
i = 48  Mean squared error      5.934936829664263
i = 47  Mean squared error      6.023534932138451
i = 46  Mean squared error      6.0090135437366055
i = 45  Mean squared error      5.9612602883304096
i = 44  Mean squared error      5.9846670744853565
i = 43  Mean squared error      5.953669659068771
i = 42  Mean squared error      5.934790321449446
i = 41  Mean squared error      5.95715003052146
i = 40  Mean squared error      5.961272578738878
i = 39  Mean squared error      5.927957117994675
i = 38  Mean squared error      5.932256206247158
i = 37  Mean squared error      5.90529359049289
i = 36  Mean squared error      5.926982214429508
i = 35  Mean squared error      5.959625719851937
i = 34  Mean squared error      5.930425161374113
i = 33  Mean squared error      5.992210183778167
i = 32  Mean squared error      5.955237155659456
i = 31  Mean squared error      6.0112496253003425
i = 30  Mean squared error      6.033933876225729
i = 29  Mean squared error      5.990675837392036
i = 28  Mean squared error      6.008592068316122
i = 27  Mean squared error      5.949876129618806
i = 26  Mean squared error      5.958884330151308
i = 25  Mean squared error      5.983731511137085
i = 24  Mean squared error      6.029017429703229
i = 23  Mean squared error      6.0264722176764725
i = 22  Mean squared error      6.031916182869017
i = 21  Mean squared error      6.0545817858302495
i = 20  Mean squared error      6.090888174556789
i = 19  Mean squared error      6.025706386128969
i = 18  Mean squared error      5.975460383141764
i = 17  Mean squared error      6.08435013182674
i = 16  Mean squared error      6.2645328982401445
i = 15  Mean squared error      6.282300540294823
i = 14  Mean squared error      6.277306030261705
i = 13  Mean squared error      6.355296960841613
i = 12  Mean squared error      6.488747114747712
i = 11  Mean squared error      6.729910427073113
i = 10  Mean squared error      6.615533820372176
i = 9   Mean squared error      6.786782114727063
i = 8   Mean squared error      6.743578447032296
i = 7   Mean squared error      6.907802311646137
i = 6   Mean squared error      7.157236917805088
i = 5   Mean squared error      8.006904046837553
i = 4   Mean squared error      8.656105489326261
i = 3   Mean squared error      8.559301682496898
i = 2   Mean squared error      7.700061717737592
i = 1   Mean squared error      7.08681324204327
Mean squared error      5.90529359049289
self.optimized_feature_number = 37
self.optimized_features = Index(['school', 'sex', 'age', 'address', 'famsize', 'studytime', 'failures',
       'nursery', 'higher', 'internet', 'romantic', 'goout', 'Dalc', 'Walc',
       'health', 'absences', 'Mjob_at_home', 'Mjob_health', 'Mjob_other',
       'Mjob_services', 'Fjob_services', 'reason_course', 'reason_home',
       'reason_other', 'reason_reputation', 'edusupport_family',
       'edusupport_no', 'parents_education', 'famrel_freetime', 'poly_0',
       'poly_1', 'poly_2', 'poly_3', 'poly_5', 'poly_6', 'poly_8', 'poly_9'],
      dtype='object')
--------------------
Modle 1 testing MES:
Mean squared error      22.140613888888875

Summary : 
Among these five experiments, Experiment 5 has the lowest validation MSE and testing MSE.
The selected features are : 
['school', 'sex', 'age', 'address', 'famsize', 'studytime', 'failures',
    'nursery', 'higher', 'internet', 'romantic', 'goout', 'Dalc', 'Walc',
    'health', 'absences', 'Mjob_at_home', 'Mjob_health', 'Mjob_other',
    'Mjob_services', 'Fjob_services', 'reason_course', 'reason_home',
    'reason_other', 'reason_reputation', 'edusupport_family',
    'edusupport_no', 'parents_education', 'famrel_freetime', 'poly_0',
    'poly_1', 'poly_2', 'poly_3', 'poly_5', 'poly_6', 'poly_8', 'poly_9']

poly_0 to poly_9 are the 2-degree polynomials of ['age', 'traveltime', 'studytime', 'absences'].

So, I would choose Experiment 5 as the best model for RandomForestRegressor.
